= OpenShift ログ集約
// Activate experimental attribute for Keyboard Shortcut keys
:experimental:

== 演習の概要
このラボでは、OpenShiftのログ集約機能を触ってみます。

OpenShift の非常に重要な機能の一つに、実行中の環境とアプリケーションポッドからログを収集して集約する機能があります。
OpenShift には柔軟性のある *EFK* によるログ集約ソリューションが同梱されています。
*EFK* は、それぞれのソリューションの頭文字を集めたものです。( *E* lasticSearch、*F* luentd、*K* ibana)

クラスタの Logging コンポーネントは、Elasticsearch、Fluentd、Kibana（EFK）をベースにしています。
コレクターである Fluentd は、OpenShift クラスタ内の各ノードにデプロイされています。
これはすべてのノードとコンテナのログを収集し、Elasticsearch（ES）に書き込みます。
Kibana は一元化された Web UI で、ユーザーや管理者は集約されたデータを使ってリッチなビジュアライゼーションやダッシュボードを作成することができます。
管理者は、すべてのログを検索することができます。
アプリケーションの所有者や開発者は、プロジェクトに属するログへのアクセスを許可することができます。
EFK スタックは OpenShift の上で動作します。

[Warning]
====
このラボでは、infra-nodes ラボを完了していることが必要です。
Logging スタックはそのラボで作成された `infra` ノードにインストールされます。
====

[Note]
====
<<<<<<< HEAD
詳細は、以下にあるOpenShiftの公式ドキュメントサイトに記載されています。:
 https://docs.openshift.com/container-platform/4.1/logging/efk-logging.html
=======
More information may be found on the official OpenShift documentation site
found here:

 https://docs.openshift.com/container-platform/4.6/logging/cluster-logging.html
>>>>>>> upstream/ocp4-dev
====

[Note]
====
この演習は、ほぼすべて OpenShift の Web コンソールを使用して行われます。
ウェブコンソールとのやりとりはすべて、事実上バックグラウンドで API オブジェクトを作成または操作しています。
プロセスを完全に自動化したり、CLIや他のツールを使用して行うことも可能ですが、これらの方法は現時点では、この演習やドキュメントではカバーされていません。
====

---

### OpenShift Logging をデプロイする

OpenShift Container Platform Cluster Logging は、デフォルト構成で使用するように設計されており、中小規模の OpenShift Container Platform クラスタ向けに調整されています。
以降のインストール手順には、サンプルの Cluster Logging Custom Resource（CR）が含まれており、これを使用して Cluster Logging インスタンスを作成し、Cluster Logging の導入を構成することができます。

デフォルトの Cluster Logging インストールを使用する場合は、サンプルCRを直接使用できます。

配置をカスタマイズしたい場合は、必要に応じてサンプル CR に変更を加えます。
以下では、Cluster Logging インスタンスのインストール時に行うことができる構成、またはインストール後に変更することができる構成について説明します。
Cluster Logging Custom Resource の外でできる変更を含め、各コンポーネントでの作業の詳細については、「構成」のセクションを参照してください。

#### `openshift-logging` namespace を作成する

OpenShift Logging は、独自の名前空間 `openshift-logging` 内で実行されます。
この名前空間はデフォルトでは存在せず、Logging をインストールする前に作成する必要があります。
名前空間は yaml 形式で以下のように表されます。:

[source,yaml]
.openshift_logging_namespace.yaml
----
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-logging
  annotations:
    openshift.io/node-selector: ""
  labels:
    openshift.io/cluster-logging: "true"
    openshift.io/cluster-monitoring: "true"
----

ネームスペースを作成するには、以下のコマンドを実行します。:

[source,bash,role="execute"]
----
oc create -f {{ HOME_PATH }}/support/openshift_logging_namespace.yaml
----


#### `Elasticsearch` と `Cluster Logging` Operator をクラスターにインストールする

`EFK` スタックをクラスタにインストールして設定するには、追加の Operator をインストールする必要があります。
これらは、クラスタ内から `Operator Hub` から GUI を介してインストールすることができます。

OpenShift で Operator を使用する際には、Operator を構成するいくつかの基本的な原理を理解しておくことが重要です。
`CustomResourceDefinion (CRD)` と `CustomResource (CR)` は、簡単に説明する 2 つの Kubernetes オブジェクトです。
`CRD` は、ジェネリックな事前定義された、データの構造体です。
Operator は、`CRD` で定義されたデータをどのように適用するかを理解します。
プログラミング的には、`CRD` はクラスに似ていると考えることができます。
`CustomResource (CR)` は、構造化されたデータが実際の値を持つ `CRD` の実際の実装です。
これらの値は、Operator がサービスを設定するときに使用するものです。
繰り返しになりますが、プログラミング用語では、`CR` はクラスのインスタンス化されたオブジェクトに似ています。

Operator を使用するための一般的なパターンは、まず Operator をインストールし、必要な `CRD` を作成します。
`CRD` が作成された後、どのように動作するか、何をインストールするか、何を設定するかを Operator に伝える `CR` を作成します。
openshift-logging　をインストールするには、このパターンに従います。

まず、OpenShift ClusterのGUIにログインします。
`{{ MASTER_URL }}`

その後、以下の手順に従ってください。:

<<<<<<< HEAD
1. Elasticsearch Operator のインストール:
  a. OpenShift コンソールから、 `Operators` → `OperatorHub` をクリックします。
  b. `Elasticsearch Operator` を、Operator リストから選択し、 `Install` をクリックします。
  c. `Create Operator Subscription` ページで、*Update Channel 4.2* を選択し、他のすべてのデフォルト設定をそのままに、`Subscribe`　をクリックします。
=======
1. Install the Elasticsearch Operator:
  a. In the OpenShift console, click `Operators` → `OperatorHub`.
  b. Choose `Elasticsearch Operator` from the list of available Operators,
    and click `Install`.
  c. On the `Create Operator Subscription` page, *select Update Channel 4.6*, leave all other defaults
     and then click `Subscribe`.
>>>>>>> upstream/ocp4-dev
+
これにより、この OpenShift Container Platform クラスタを使用するすべてのユーザーとプロジェクトがこの Operator を利用できるようになります。

2. Cluster Logging Operator のインストール:
+
[Note]
====
`Cluster Logging` Operator を  `openshift-logging` ネームスペースにインストールする必要があります。
`openshift-logging` ネームスペースが前の手順で作成されたことを確認してください。
====

<<<<<<< HEAD
  a. OpenShift コンソールで、`Operators` → `OperatorHub` をクリックします。
  b. 利用可能な Operator のリストから `Cluster Logging` を選択し、`Install` をクリックする。
  c. `Create Operator Subscription` ページで、`Installation Mode` で、クラスタ上の特定の名前空間が選択されていることを確認し、`openshift-logging` を選択します。
     さらに、*select Update Channel 4.2* を選択し、他のすべてのデフォルトを残してから `Subscribe` をクリックします。
=======
  a. In the OpenShift console, click `Operators` → `OperatorHub`.
  b. Choose `Cluster Logging` from the list of available Operators, and click
    `Install`.
  c. On the `Create Operator Subscription` page, Under ensure `Installation
     Mode` that `A specific namespace on the cluster` is selected, and choose
     `openshift-logging`. In addition, *select Update Channel 4.6* and leave all other defaults
     and then click `Subscribe`.
>>>>>>> upstream/ocp4-dev

3. Operator のインストールを確認する。:

  a. `Operators` → `Installed Operators` のページに切り替える。

  b. `openshift-logging` プロジェクトが選択されていることを確認する。

  c. _Status_ 列で、緑色のチェックで、 `InstallSucceeded` もしくは `Copied` そして _Up to date_ のテキストが見えるはずです。
+
[Note]
====
インストール中に Operator が `Failed` ステータスを表示することがあります。
Operator が  `InstallSucceeded` メッセージを表示してインストールが完了した場合、`Failed` メッセージを無視しても問題ありません。
====

4. トラブルシューティング (オプショナル)
+
どちらかの Operator がインストールされているように表示されない場合は、さらにトラブルシューティングを行います。:
+
* Installed Operators ページの Copied タブで、Operator に Status of Copied が表示されている場合、これはインストールが進行中であり、期待される動作であることを示しています。
+
* Catalog → Operator Management ページに切り替え、Operator Subscriptions and Install Plans のタブで、ステータスの下に障害やエラーがないかどうかを確認します。
+
* Workloads → Pods のページに切り替えて、openshift-logging と openshift-operators プロジェクトで問題を報告している任意の Pod のログを確認します。


#### Logging `CustomResource (CR)` インスタンスを作成する

Operator を `CRD` と一緒にインストールしたので、Logging `CR` を作成して、Logging のインストールを開始します。
これは、Logging をインストールして設定する方法を定義します。

1. OpenShift Consoleで、`Administration` → `Custom Resource Definitions` ページに切り替えます。

2. `Custom Resource Definitions` のページで、 `ClusterLogging` をクリックする。

3. `Custom Resource Definition Overview` ページで、`Actions` メニューから `View Instances` を選択する。
+
[Note]
====
`404` のエラーが表示されても、慌てないでください。
Operator のインストールは成功したものの、Operator 自体のインストールが完了しておらず、 `CustomResourceDefinition` がまだ作成されていない可能性があります。
しばらく待ってからページを更新してください。
====
+
4. `Cluster Loggings` ページで、 `Create Cluster Logging` をクリックします。
+
[Warning]
====
このステップに入る前に、`Deploying and Managing OpenShift Container Storage` モジュールを完了している必要があります。
`OCS` モジュールが完了していない場合は、エディタにコピーする前に、以下の `YAML` の `storageClassName: ocs-storagecluster-ceph-rbd` を `storageClassName: gp2` で置き換える必要があります。
====

5. `YAML` エディタで、コードを以下で置き換えます。:

[source,yaml]
.openshift_logging_cr.yaml
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    elasticsearch:
      nodeCount: 3
      storage:
         storageClassName: ocs-storagecluster-ceph-rbd
         size: 100Gi
      redundancyPolicy: "SingleRedundancy"
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      resources:
        request:
          memory: 4G
  visualization:
    type: "kibana"
    kibana:
      replicas: 1
      nodeSelector:
        node-role.kubernetes.io/infra: ""
  curation:
    type: "curator"
    curator:
      schedule: "30 3 * * *"
      nodeSelector:
        node-role.kubernetes.io/infra: ""
  collection:
    logs:
      type: "fluentd"
      fluentd: {}
      nodeSelector:
        node-role.kubernetes.io/infra: ""
----

そして `Create` をクリックします。

#### Logging インストールを確認する

Logging が作成されたので、動作しているかどうかを確認してみましょう。

1. `Workloads` → `Pods` ページに移動します。

2. `openshift-logging` プロジェクトを選択します。

クラスタ Logging （Operator 自身）、Elasticsearch、Fluentd、Kibana　のポッドが表示されているはずです。

または、次のコマンドを使用してコマンドラインから検証することもできます。:

[source,bash,role="execute"]
----
oc get pods -n openshift-logging
----

最終的には、次のようなものが表示されるはずです。:

----
NAME                                            READY   STATUS    RESTARTS   AGE
cluster-logging-operator-cb795f8dc-xkckc        1/1     Running   0          32m
elasticsearch-cdm-b3nqzchd-1-5c6797-67kfz       2/2     Running   0          14m
elasticsearch-cdm-b3nqzchd-2-6657f4-wtprv       2/2     Running   0          14m
elasticsearch-cdm-b3nqzchd-3-588c65-clg7g       2/2     Running   0          14m
fluentd-2c7dg                                   1/1     Running   0          14m
fluentd-9z7kk                                   1/1     Running   0          14m
fluentd-br7r2                                   1/1     Running   0          14m
fluentd-fn2sb                                   1/1     Running   0          14m
fluentd-pb2f8                                   1/1     Running   0          14m
fluentd-zqgqx                                   1/1     Running   0          14m
kibana-7fb4fd4cc9-bvt4p                         2/2     Running   0          14m
----

_Fluentd_ *Pods* は、 *DaemonSet* としてデプロイされます。*DaemonSet* は、特定の *Pods* が、クラスタ内の特定の *Nodes* で常に実行されるための仕組みです。:


[source,bash,role="execute"]
----
oc get daemonset -n openshift-logging
----

以下のようなものを見ることができます。:

----
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
fluentd   9         9         9       9            9           kubernetes.io/os=linux   94s
----

クラスタ内の *Node* ごとに1つの `fluentd` *Pod* が必要です。
*Master* も *Node* であり、`fluentd` はそこでも様々なログを読み取るために実行されることを覚えておいてください。

また、ElasticSearch 用のストレージが自動的にプロビジョニングされていることがわかります。
このプロジェクトの *PersistentVolumeClaim* オブジェクトにクエリを実行すると、新しいストレージが表示されます。

[source,bash,role="execute"]
----
oc get pvc -n openshift-logging
----

以下のようなものが見えるはずです。:

----
NAME                                         STATUS   VOLUME                                     CAPACITY   ACCESS
MODES   STORAGECLASS                  AGE
elasticsearch-elasticsearch-cdm-ggzilasv-1   Bound    pvc-f3239564-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
elasticsearch-elasticsearch-cdm-ggzilasv-2   Bound    pvc-f324a252-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
elasticsearch-elasticsearch-cdm-ggzilasv-3   Bound    pvc-f326aa7d-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
----		

[Note]
====
Metrics ソリューションの場合と同様に、Logging の構成( `CR` )で適切な `NodeSelector` を定義して、Logging コンポーネントが infra ノードにしかデプロイされないようにしています。
つまり、`DaemonSet` は FluentD が *すべての* ノードで実行されることを保証しています。
そうでなければ、すべてのコンテナログをキャプチャすることはできません。
====

#### _Kibana_ にアクセスする

前述の通り、_Kibana_ はフロントエンドであり、ユーザーや管理者が OpenShift Logging スタックにアクセスするためのインターフェイスです。
_Kibana_ ユーザーインターフェースにアクセスするには、まず Kibana の *Service* を公開するために設定された *Route* を見て、そのパブリックアクセス URL を調べます。:

_Kibana_ route を見つけてアクセスするには:

1. OpenShift console から、 `Networking` → `Routes` ページをクリックします。

2. `openshift-logging` プロジェクトを選択します。

3. `Kibana` route をクリックします。

4. `Location` フィールドで、表示されている URL をクリックします。

5.  SSL 証明書をアクセプトします。

あるいは、コマンドラインから取得することもできます。:

[source,bash,role="execute"]
----
oc get route -n openshift-logging
----

以下のようなものが見えるはずです。:

----
NAME     HOST/PORT                                                           PATH   SERVICES   PORT    TERMINATION          WILDCARD
kibana   kibana-openshift-logging.{{ ROUTE_SUBDOMAIN }}          kibana     <all>   reencrypt/Redirect   None
----

または、control+click  をクリックすることができます。:

https://kibana-openshift-logging.{{ ROUTE_SUBDOMAIN }}

EFK インストールの一部として設定されている特別な認証プロキシがあり、その結果、Kibana はアクセスに OpenShift の資格情報を必要とします。

OpenShift Console に cluster-admin ユーザーとして認証済みのため、Kibana の管理画面が表示されます。

<<<<<<< HEAD
#### _Kibana_ を使ってクエリを行う
=======
#### Setting up Index Patterns

Once you open Kibana, before being able to view logs, we need to define an `index pattern` that will be used by Kibana to query ElasticSearch.

1. On the following screen, input `app*` as the index pattern, as shown below and hit `Next Step`.
+
image::images/logging-kibana-indexpattern.png[Kibana Index Pattern]
+

2. On the following screen, input `infra*` as the index pattern, as shown below and hit `Next Step`.
+
image::images/logging-kibana-indexpattern-infra.png[Kibana Index Pattern]
+

3. On the next screen, select `Timestamp` in the drop-down box, as shown below:
+
image::images/logging-kibana-indexpattern-timestamp.png[Kibana Index Pattern]
+

4. Hit Create Index Pattern

#### Queries with _Kibana_
>>>>>>> upstream/ocp4-dev

_Kibana_ の Web インターフェースが立ち上がったら、クエリを実行できるようになります。
_Kibana_ は、クラスタから送られてくるすべてのログを問い合わせるための強力なインターフェイスをユーザに提供します

デフォルトでは、_Kibana_　は過去15分以内に受信したすべてのログを表示します。
この時間間隔は右上で変更できます。
ログメッセージはページの中央に表示されます。
受信したすべてのログメッセージは、ログメッセージの内容に基づいてインデックス化されます。
各メッセージには、そのログメッセージに関連付けられたフィールドがあります。
個々のメッセージを構成するフィールドを見るには、ページの中央にある各メッセージの側面にある矢印をクリックします。
これにより、含まれているメッセージ フィールドが表示されます。

まず、デフォルトのインデックスパターンを `.all` に設定します。
左側から上に向かって、ドロップダウンメニューで `.all` のインデックスパターンを選択します。

メッセージに表示するフィールドを選択するには、左側の `Available Fields` ラベルの手前を見てください。
その下には選択可能なフィールドがあり、画面の中央に表示されます。
利用可能なフィールド `Available Fields` の下にある `hostname` フィールドを見つけて、 `add` をクリックします。
これで、メッセージペインに各メッセージのホスト名が表示されることに気づくでしょう。
これ以外にもフィールドを追加することができます。 `kubernetes.pod_name` と `message` の `add` ボタンをクリックします。

ログに対するクエリを作成するには、検索ボックスの右下にある `Add a filter +` リンクを使用することができます。
これにより、メッセージのフィールドを使ってクエリを作成することができます。
例えば、 `openshift-logging` namespace のすべてのログメッセージを見たい場合、以下のようにします。:

1. `Add a filter +` をクリックします。

2. `Fields` インプットボックスで、 `kubernetes.namespace_name` とタイプします。
クエリをビルドするための全ての可能なフィールドがある事に注目してください。

3. 次に、 `is` を選択します。

4. `Value` フィールドで、 `openshift-logging`　とタイプします。

5. "Save" ボタンをクリックします。

さて、画面の中央には `openshift-logging` namespace にあるすべてのポッドからのログが表示されているはずです。

もちろん、さらにフィルタを追加してクエリを絞り込むこともできます。

Kibanaでは、クエリを保存して後で使えるようにすることができます。クエリを保存するには、以下のようにします。:

1. 画面上部の `Save` をクリックする。

2. 保存したい名前を入力します。ここでは、`openshift-logging Namespace` と入力します。

一度保存しておけば、後で `Open` ボタンを押してこのクエリを選択することで利用することができます。

<<<<<<< HEAD
時間をかけて _Kibana_ のページを探索し、より多くのクエリを追加したり実行したりして経験を積んでください。
これは本番環境のクラスタを使用する際に役立つでしょう。
探しているログをこのコンソールから取得することができるようになります。
=======
Please take time to explore the _Kibana_ page and get experience by adding
and doing more queries. This will be helpful when using a production cluster,
you will be able to get the exact logs that you are looking for in a single
place.

### Forwarding logs to external systems
In this section we will show you how to use a new feature in OpenShift 4.6 to ease forwarding logs to external log systems.

A new CustomResourceDefinition (CRD) named `ClusterLogForwarder` is used by the `Cluster Logging Operator` to create or modify internal Fluentd configmaps to forward logs to external (or internal) systems.
Only one `ClusterLogForwarder` can exist in a cluster, and it combines all of the log forwarding rules.

Forwarding cluster logs to external third-party systems requires a combination of `outputs` and `pipelines` specified in a `ClusterLogForwarder` custom resource (CR) to send logs to specific endpoints inside and outside of your OpenShift Container Platform cluster. You can also use `inputs` to forward the application logs associated with a specific project to an endpoint. Let's learn more about these concepts.

* An `output` is the destination for log data that you define, or where you want the logs sent. An output can be one of the following types:

** `elasticsearch`: An external Elasticsearch v5.x or v6.x instance. The elasticsearch output can use a TLS connection.

** `fluentdForward`: An external log aggregation solution that supports Fluentd. This option uses the Fluentd forward protocols. The fluentForward output can use a TCP or TLS connection and supports shared-key authentication by providing a shared_key field in a secret. Shared-key authentication can be used with or without TLS.

** `syslog`: An external log aggregation solution that supports the syslog RFC3164 or RFC5424 protocols. The syslog output can use a UDP, TCP, or TLS connection.

** `kafka`: A Kafka broker. The kafka output can use a TCP or TLS connection.

** `default`: The internal OpenShift Container Platform Elasticsearch instance. You are not required to configure the default output. If you do configure a default output, you receive an error message because the default output is reserved for the Cluster Logging Operator.

If the output URL scheme requires TLS (HTTPS, TLS, or UDPS), then TLS server-side authentication is enabled. To also enable client authentication, the output must name a secret in the openshift-logging project. The secret must have keys of: tls.crt, tls.key, and ca-bundle.crt that point to the respective certificates that they represent.

* A `pipeline` defines simple routing from one log type to one or more outputs, or which logs you want to send. The log types are one of the following:

** `application`: Container logs generated by user applications running in the cluster, except infrastructure container applications.

** `infrastructure`: Container logs from pods that run in the openshift*, kube*, or default projects and journal logs sourced from node file system.

** `audit`: Logs generated by the node audit system (auditd) and the audit logs from the Kubernetes API server and the OpenShift API server.

You can add labels to outbound log messages by using key:value pairs in the pipeline. For example, you might add a label to messages that are forwarded to others data centers or label the logs by type. Labels that are added to objects are also forwarded with the log message.

* An input forwards the application logs associated with a specific project to a pipeline.



[Note]
====
More information may be found on the official OpenShift documentation site
found here:


https://docs.openshift.com/container-platform/4.6/logging/cluster-logging-external.html
====


#### Sending logs to an external Syslog server
For the sake of simplification, we will emulate an external Syslog server by deploying a containerized Syslog server in a namespace called `external-logs`.

Since we also want to show how to separate application logs from infrastructure logs, we will deploy 2 'external' (containerized) Syslogs, one to receive forwarded application logs, and one to receive forwarded infrastructure logs.

First, let's create a namespace called `external-logs` where we will deploy the Syslog server.

[source,bash,role="execute"]
----
oc new-project external-logs
----

Now, let's deploy the `Syslog` servers on that namespace. For that, we'll be using a YAML file containing all the required resources:
[source,bash,role="execute"]
----
oc create -f /opt/app-root/src/support/extlogs-syslog.yaml -n external-logs
----

Let's check that everything is working fine, which can take a minute until the image is pulled for an external registry. When everything is OK, we should get an output similar to this:
```
NAME                              READY   STATUS    RESTARTS   AGE
syslog-ng-7cff7dd94-t5hh7         1/1     Running   0          1m
```

Now that our external Syslog server is available, let's setup a log forwarding rule by creating a `ClusterLogForwarder`.
First let's look at the YAML file:

```YAML
apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging
spec:
  outputs: <1>
  - name: rsyslog-app
    syslog:
      facility: user
      payloadKey: message
      rfc: RFC3164
      severity: informational
    type: syslog <2>
    url: udp://syslog-ng.external-logs.svc:514 <3>
  - name: rsyslog-infra
    syslog:
      facility: user
      payloadKey: message
      rfc: RFC3164
      severity: informational
    type: syslog
    url: udp://syslog-ng-infra.external-logs.svc:514 <4>
  pipelines: <5>
  - inputRefs: <6>
    - application <7>
    labels:
      syslog: app
    name: syslog-app
    outputRefs:
    - rsyslog-app <8>
    - default
  - inputRefs:
    - infrastructure <8>
    labels:
      syslog: infra
    name: syslog-infra
    outputRefs:
    - rsyslog-infra <9>
    - default
```

In this YAML file, there are some notable fields:

 The `outputs` (1) section defines all the remote log systems, in our case we have 2 Syslog servers:

** (3) This is the url for the one to store application-related logs. It is pointing to the service that is in the `external-logs` namespace.
** (4) This is the url one for infrastructure-related logs. It is pointing to the service that is in the `external-logs` namespace.

The `pipelines` section defines the sources and nature of logs that should be sent to the outputs defined before.
`inputRefs` are used to describe the nature of the log to be sent, and as a reminder they can be either `application`, `infrastructure`, or `audit` for OpenShift audit logs (API access, etc).

We have 2 inputsRefs, (7) is for application logs and (8) is for infrastructure logs.
Each inputRefs section contains an outRefs to tell where the logs should be sent, referring the outputs (1) defined in the beginning of the spec section.

Now let's create the ClusterLogForwareder resource using the YAML file:

[source,bash,role="execute"]
----
oc create -f /opt/app-root/src/support/extlogs-clusterlogforwarder.yaml
----

Once the CR is created, the Cluster Logging Operator redeploys the Fluentd pods. 
If the pods do not redeploy, you can delete the Fluentd pods to force them to redeploy.

[source,bash,role="execute"]
----
oc delete pod --selector logging-infra=fluentd -n openshift-logging
----

Let's check that all the Fluentd pods are now in Running state:

[source,bash,role="execute"]
----
oc get pod --selector logging-infra=fluentd -n openshift-logging
----

You should see something like this in the output:
```
NAME            READY   STATUS        RESTARTS   AGE
fluentd-274bx   1/1     Running       0          1m
fluentd-5bqx8   1/1     Running       0          1m
fluentd-67qld   1/1     Running       0          1m
fluentd-m9v2f   1/1     Running       0          1m
fluentd-vs8bb   1/1     Running       0          1m
fluentd-x98gk   1/1     Running       0          1m
```

Now let's check that the logs are being forwarded to the 2 Syslog servers. 
The Syslog server stores it's logs in the /var/log/messages file within the container, so we need to check it's content by doing an oc exec into the container. `Make sure you put the correct pod name in the command`:

We will be using the OpenShift Console Terminal to access the pod and check the `/var/log/messages` content.

1. Open the Administrator View and go to `workloads->Pods`
+
image::images/logging-syslog-pods.png[Syslog Pods]
+

2. Click on the syslog infrastructure pod, which name looks like `syslog-ng-infra-xyz`, and go the the `Terminal` tab
+
image::images/logging-syslog-terminal-infra.png[Syslog Terminal]
+

3. In the Terminal box, enter this command: `tail -f /var/log/messages`. The forwarded logs should then appear in the terminal.
+
image::images/logging-syslog-logs.png[Syslog logs]
+

And voilà! You can repeat this procedure with the other pod to check that the application logs are correctly forwarded too. 

>>>>>>> upstream/ocp4-dev
