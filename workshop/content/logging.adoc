= OpenShift ログ集約
// Activate experimental attribute for Keyboard Shortcut keys
:experimental:

== 演習の概要
このラボでは、OpenShiftのログ集約機能を触ってみます。

OpenShift の非常に重要な機能の一つに、実行中の環境とアプリケーションポッドからログを収集して集約する機能があります。
OpenShift には柔軟性のある *EFK* によるログ集約ソリューションが同梱されています。
*EFK* は、それぞれのソリューションの頭文字を集めたものです。( *E* lasticSearch、*F* luentd、*K* ibana)

クラスタの Logging コンポーネントは、Elasticsearch、Fluentd、Kibana（EFK）をベースにしています。
コレクターである Fluentd は、OpenShift クラスタ内の各ノードにデプロイされています。
これはすべてのノードとコンテナのログを収集し、Elasticsearch（ES）に書き込みます。
Kibana は一元化された Web UI で、ユーザーや管理者は集約されたデータを使ってリッチなビジュアライゼーションやダッシュボードを作成することができます。
管理者は、すべてのログを検索することができます。
アプリケーションの所有者や開発者は、プロジェクトに属するログへのアクセスを許可することができます。
EFK スタックは OpenShift の上で動作します。

[Warning]
====
このラボでは、infra-nodes ラボを完了していることが必要です。
Logging スタックはそのラボで作成された `infra` ノードにインストールされます。
====

[Note]
====
詳細は、以下にあるOpenShiftの公式ドキュメントサイトに記載されています。:
 https://docs.openshift.com/container-platform/4.10/logging/cluster-logging.html
====

[Note]
====
この演習は、ほぼすべて OpenShift の Web コンソールを使用して行われます。
ウェブコンソールとのやりとりはすべて、事実上バックグラウンドで API オブジェクトを作成または操作しています。
プロセスを完全に自動化したり、CLIや他のツールを使用して行うことも可能ですが、これらの方法は現時点では、この演習やドキュメントではカバーされていません。
====

---

### OpenShift Logging をデプロイする

OpenShift Container Platform Cluster Logging は、デフォルト構成で使用するように設計されており、中小規模の OpenShift Container Platform クラスタ向けに調整されています。
以降のインストール手順には、サンプルの Cluster Logging Custom Resource（CR）が含まれており、これを使用して Cluster Logging インスタンスを作成し、Cluster Logging の導入を構成することができます。

デフォルトの Cluster Logging インストールを使用する場合は、サンプルCRを直接使用できます。

配置をカスタマイズしたい場合は、必要に応じてサンプル CR に変更を加えます。
以下では、Cluster Logging インスタンスのインストール時に行うことができる構成、またはインストール後に変更することができる構成について説明します。
Cluster Logging Custom Resource の外でできる変更を含め、各コンポーネントでの作業の詳細については、「構成」のセクションを参照してください。

#### `openshift-logging` namespace を作成する

OpenShift Logging は、独自の名前空間 `openshift-logging` 内で実行されます。
この名前空間はデフォルトでは存在せず、Logging をインストールする前に作成する必要があります。
名前空間は yaml 形式で以下のように表されます。:

[source,yaml]
.openshift_logging_namespace.yaml
----
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-logging
  annotations:
    openshift.io/node-selector: ""
  labels:
    openshift.io/cluster-logging: "true"
    openshift.io/cluster-monitoring: "true"
----

ネームスペースを作成するには、以下のコマンドを実行します。:

[source,bash,role="execute"]
----
oc create -f {{ HOME_PATH }}/support/openshift_logging_namespace.yaml
----


#### `Elasticsearch` と `Cluster Logging` Operator をクラスターにインストールする

`EFK` スタックをクラスタにインストールして設定するには、追加の Operator をインストールする必要があります。
これらは、クラスタ内から `Operator Hub` から GUI を介してインストールすることができます。

OpenShift で Operator を使用する際には、Operator を構成するいくつかの基本的な原理を理解しておくことが重要です。
`CustomResourceDefinion (CRD)` と `CustomResource (CR)` は、Kubernetes オブジェクトであり、簡単に説明すると以下の通りです。
`CRD` は、ジェネリックな事前定義された、データの構造体です。
Operator は、`CRD` で定義されたデータをどのように適用するかを理解します。
プログラミング的には、`CRD` はクラスに似ていると考えることができます。
`CustomResource (CR)` は、構造化されたデータが実際の値を持つ `CRD` の実際の実装です。
これらの値は、Operator がサービスを設定するときに使用するものです。
繰り返しになりますが、プログラミング用語では、`CR` はクラスのインスタンス化されたオブジェクトに似ています。

Operator を使用するための一般的なパターンは、まず Operator をインストールし、必要な `CRD` を作成します。
`CRD` が作成された後、どのように動作するか、何をインストールするか、何を設定するかを Operator に伝える `CR` を作成します。
openshift-logging をインストールするには、このパターンに従います。

まず、OpenShift ClusterのGUIにログインします。
`{{ MASTER_URL }}`

その後、以下の手順に従ってください。:

1. Elasticsearch Operator のインストール:
  a. OpenShift コンソールから、 `Operators` → `OperatorHub` をクリックします。
  b. 検索フィールドに `Elasticsearch Operator` と入力し、使用可能なオペレーターのリストから `OpenShift Elasticsearch Operator` を選択し、 `Install` をクリックします。
  c. `Create Operator Subscription` ページで、Update Channelにて *Stable* を選択し、他のすべてのデフォルト設定をそのままに、`Subscribe` をクリックします。
+
これにより、この OpenShift Container Platform クラスタを使用するすべてのユーザーとプロジェクトがこの Operator を利用できるようになります。

2. Cluster Logging Operator のインストール:
+
[Note]
====
`Cluster Logging` Operator を  `openshift-logging` ネームスペースにインストールする必要があります。
`openshift-logging` ネームスペースが前の手順で作成されたことを確認してください。
====

  a. OpenShift コンソールで、`Operators` → `OperatorHub` をクリックします。
  b. 検索フィールドに `OpenShift Logging` と入力し、使用可能なオペレーターのリストから `Red Hat OpenShift Logging` を選択し、 `Install` をクリックします。
  c. `Create Operator Subscription` ページで、`Update Channel` にて *Stable* を選択します。また `Installation Mode` で、*A specific namespace on the cluster* が選択されていることを確認し、`Installed Namespace` にて *openshift-logging* が設定されていることを確認します。他のすべてのデフォルト設定をそのままに、`Subscribe` をクリックします。

3. Operator のインストールを確認する。:

  a. `Operators` → `Installed Operators` のページに切り替えます。

  b. 画面上部のプロジェクト選択にて `Show default projects` のトグルをONにした後、 `openshift-logging` プロジェクトを選択します。

  c. _Status_ 列で、緑色のチェックで、 `InstallSucceeded` もしくは `Copied` そして _Up to date_ のテキストが見えるはずです。
+
[Note]
====
インストール中に Operator が `Failed` ステータスを表示することがあります。
Operator が  `InstallSucceeded` メッセージを表示してインストールが完了した場合、`Failed` メッセージを無視しても問題ありません。
====

4. トラブルシューティング (オプショナル)
+
どちらかの Operator がインストールされているように表示されない場合は、さらにトラブルシューティングを行います。:
+
* `Installed Operators` ページで該当のOperatorを選択し、`Subscription` のタブで、ステータスの下に障害やエラーがないかどうかを確認します。
+
* `Workloads` → `Pods` のページに切り替えて、`openshift-logging` と `openshift-operators` プロジェクトで問題を報告している任意の `Pod` のログを確認します。


#### Logging `CustomResource (CR)` インスタンスを作成する

Operator を `CRD` と一緒にインストールしたので、Logging `CR` を作成して、Logging のインストールを開始します。
これは、Logging をインストールして設定する方法を定義します。

1. OpenShift Consoleで、`Administration` → `Custom Resource Definitions` ページに切り替えます。

2. `Custom Resource Definitions` のページで、 `ClusterLogging` をクリックします。

3. `Custom Resource Definition Overview` ページで、`Actions` メニューから `View Instances` を選択する。
+
[Note]
====
`404` のエラーが表示されても、慌てないでください。
Operator のインストールは成功したものの、Operator 自体のインストールが完了しておらず、 `CustomResourceDefinition` がまだ作成されていない可能性があります。
しばらく待ってからページを更新してください。
====
+
4. `Cluster Loggings` ページで、 `Create Cluster Logging` をクリックします。
+
[Warning]
====
このステップに入る前に、`OpenShift Data Foundation(ODF)` モジュールを完了している必要があります。
`ODF` モジュールが完了していない場合は、エディタにコピーする前に、以下の `YAML` の `storageClassName: ocs-storagecluster-ceph-rbd` を `storageClassName: gp2` で置き換える必要があります。
====

5. `YAML` エディタで、コードを以下で置き換えます。:

[source,yaml]
.openshift_logging_cr.yaml
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    elasticsearch:
      nodeCount: 3
      storage:
         storageClassName: ocs-storagecluster-ceph-rbd
         size: 100Gi
      redundancyPolicy: "SingleRedundancy"
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      resources:
        request:
          memory: 4G
  visualization:
    type: "kibana"
    kibana:
      replicas: 1
      nodeSelector:
        node-role.kubernetes.io/infra: ""
  curation:
    type: "curator"
    curator:
      schedule: "30 3 * * *"
      nodeSelector:
        node-role.kubernetes.io/infra: ""
  collection:
    logs:
      type: "fluentd"
      fluentd: {}
      nodeSelector:
        node-role.kubernetes.io/infra: ""
----

そして `Create` をクリックします。

#### Logging インストールを確認する

Logging が作成されたので、動作しているかどうかを確認してみましょう。

1. `Workloads` → `Pods` ページに移動します。

2. `openshift-logging` プロジェクトを選択します。

クラスタ Logging （Operator 自身）、Elasticsearch、Fluentd、Kibana のポッドが表示されているはずです。

または、次のコマンドを使用してコマンドラインから検証することもできます。:

[source,bash,role="execute"]
----
oc get pods -n openshift-logging
----

最終的には、次のようなものが表示されるはずです。:

----
NAME                                            READY   STATUS    RESTARTS   AGE
cluster-logging-operator-5d4b6f7b99-ksr5s       1/1     Running   0          113s
collector-2p5fx                                 2/2     Running   0          26s
collector-7lw5r                                 2/2     Running   0          42s
collector-8stvf                                 2/2     Running   0          32s
collector-b7qs8                                 2/2     Running   0          27s
collector-clfsc                                 2/2     Running   0          16s
collector-f2tzf                                 2/2     Running   0          31s
collector-j6hxp                                 2/2     Running   0          10s
collector-kdvj8                                 2/2     Running   0          30s
collector-q6wck                                 2/2     Running   0          21s
collector-sgndk                                 2/2     Running   0          17s
collector-w5ds9                                 2/2     Running   0          29s
collector-zswpb                                 2/2     Running   0          34s
elasticsearch-cdm-mnc985r3-1-5c45b9bd9f-4nx56   2/2     Running   0          70s
elasticsearch-cdm-mnc985r3-2-779989b7bb-z9dpp   1/2     Running   0          69s
elasticsearch-cdm-mnc985r3-3-6d754c8cbf-fx8wd   1/2     Running   0          68s
kibana-655877db88-njsqq                         2/2     Running   0          70s
----

_collector_ *Pods* は、 *DaemonSet* としてデプロイされます。*DaemonSet* は、特定の *Pods* が、クラスタ内の特定の *Nodes* で常に実行されるための仕組みです。:


[source,bash,role="execute"]
----
oc get daemonset -n openshift-logging
----

以下のようなものを見ることができます。:

----
NAME        DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
collector   10        10        10      10           10          kubernetes.io/os=linux   2m55s
----

クラスタ内の *Node* ごとに1つの `collector` *Pod* が必要です。
*Master* も *Node* であり、`collector` はそこでも様々なログを読み取るために実行されることを覚えておいてください。

また、ElasticSearch 用のストレージが自動的にプロビジョニングされていることがわかります。
このプロジェクトの *PersistentVolumeClaim* オブジェクトにクエリを実行すると、新しいストレージが表示されます。

[source,bash,role="execute"]
----
oc get pvc -n openshift-logging
----

以下のようなものが見えるはずです。:

----
NAME                                         STATUS   VOLUME                                     CAPACITY   ACCESS
MODES   STORAGECLASS                  AGE
elasticsearch-elasticsearch-cdm-ggzilasv-1   Bound    pvc-f3239564-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
elasticsearch-elasticsearch-cdm-ggzilasv-2   Bound    pvc-f324a252-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
elasticsearch-elasticsearch-cdm-ggzilasv-3   Bound    pvc-f326aa7d-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
----		

[Note]
====
Metrics ソリューションの場合と同様に、Logging 構成( `CR` )で適切な `NodeSelector` を定義して、Logging コンポーネントが infra ノードにしかデプロイされないようにしています。
つまり、`DaemonSet` は FluentD が *すべての* ノードで実行されることを保証しています。
そうでなければ、すべてのコンテナログをキャプチャすることはできません。
====

#### _Kibana_ にアクセスする

前述の通り、_Kibana_ はフロントエンドであり、ユーザーや管理者が OpenShift Logging スタックにアクセスするためのインターフェイスです。
_Kibana_ ユーザーインターフェースにアクセスするには、まず Kibana の *Service* を公開するために設定された *Route* を見て、そのパブリックアクセス URL を調べます。:

_Kibana_ route を見つけてアクセスするには:

1. OpenShift console から、 `Networking` → `Routes` ページをクリックします。

2. `openshift-logging` プロジェクトを選択します。

3. `Kibana` route をクリックします。

4. `Location` フィールドで、表示されている URL をクリックします。

5.  SSL 証明書をアクセプトします。

あるいは、コマンドラインから取得することもできます。:

[source,bash,role="execute"]
----
oc get route -n openshift-logging
----

以下のようなものが見えるはずです。:

----
NAME     HOST/PORT                                                           PATH   SERVICES   PORT    TERMINATION          WILDCARD
kibana   kibana-openshift-logging.{{ ROUTE_SUBDOMAIN }}          kibana     <all>   reencrypt/Redirect   None
----

または、control+click  をクリックすることができます。:

https://kibana-openshift-logging.{{ ROUTE_SUBDOMAIN }}

EFK インストールの一部として設定されている特別な認証プロキシがあり、その結果、Kibana はアクセスに OpenShift の資格情報を必要とします。

OpenShift Console に cluster-admin ユーザーとして認証済みのため、Kibana の管理画面が表示されます。

#### インデックスパターンの設定

Kibanaを開いたら、ログを表示する前に、 KibanaがElasticSearchにクエリを実行するために使用する `index pattern` を定義する必要があります。

1. 次の画面で、下図のようにインデックスパターンに `app*` と入力し、 `Next Step` をクリックします。
+
image::images/logging-kibana-indexpattern.png[]
+
2. 次の画面で、以下に示すように、ドロップダウンボックスで `@timestamp` を選択します。
+
image::images/logging-kibana-indexpattern-timestamp.png[]
+
3. `Create Index Pattern` をクリックします。
4. 以下の概要画面が表示されます。
+
image::images/kibana-summary-ip.png[]
+
5. 画面左上の `Discover` をクリックします

#### _Kibana_ を使ってクエリを行う

_Kibana_ の Web インターフェースが立ち上がったら、クエリを実行できるようになります。
_Kibana_ は、クラスタから送られてくるすべてのログを問い合わせるための強力なインターフェイスをユーザに提供します。

デフォルトでは、_Kibana_ は過去15分以内に受信したすべてのログを表示します。
この時間間隔は右上で変更できます。
ログメッセージはページの中央に表示されます。
受信したすべてのログメッセージは、ログメッセージの内容に基づいてインデックス化されます。
各メッセージには、そのログメッセージに関連付けられたフィールドがあります。
個々のメッセージを構成するフィールドを見るには、ページの中央にある各メッセージの側面にある矢印をクリックします。
これにより、含まれているメッセージ フィールドが表示されます。

メッセージに表示するフィールドを選択するには、左側の `Available Fields` ラベルの手前を見てください。
その下には選択可能なフィールドがあり、画面の中央に表示されます。
利用可能なフィールド `Available Fields` の下にある `hostname` フィールドを見つけて、 `add` をクリックします。
これで、メッセージペインに各メッセージのホスト名が表示されることに気づくでしょう。
これ以外にもフィールドを追加することができます。 `kubernetes.pod_name` と `message` の `add` ボタンをクリックします。

ログに対するクエリを作成するには、検索ボックスの右下にある `Add a filter +` リンクを使用することができます。
これにより、メッセージのフィールドを使ってクエリを作成することができます。
例えば、 `lab-ocp-cns` namespace のすべてのログメッセージを見たい場合、以下のようにします。:

1. `Add a filter +` をクリックします。

2. `Fields` インプットボックスで、 `kubernetes.namespace_name` とタイプします。
クエリをビルドするための全ての可能なフィールドがある事に注目してください。

3. 次に、 `is` を選択します。

4. `Value` フィールドで、 `lab-ocp-cns` とタイプします。

5. "Save" ボタンをクリックします。

画面の中央には `lab-ocp-cns` namespace にあるすべてのポッドからのログが表示されているはずです。

もちろん、さらにフィルタを追加してクエリを絞り込むこともできます。

Kibanaでは、クエリを保存して後で使えるようにすることができます。クエリを保存するには、以下のようにします。:

1. 画面上部の `Save` をクリックします。

2. 保存したい名前を入力します。ここでは、`lab-ocp-cns Namespace` と入力します。

一度保存しておけば、後で `Open` ボタンを押してこのクエリを選択することで利用することができます。

時間をかけて _Kibana_ のページを探索し、より多くのクエリを追加したり実行したりして経験を積んでください。
これは本番環境のクラスタを使用する際に役立つでしょう。
探しているログをこのコンソールから取得することができるようになります。