## OpenShift ログ集約
このラボでは、OpenShiftのロギングアグリゲーション機能を調査します。

OpenShift の非常に重要な機能は、実行中の環境とアプリケーションポッドからログを収集して集約することです。
OpenShift には柔軟性のある *EFK* によるログ集約ソリューションが同梱されています。
*EFK* は、それぞれのソリューションの頭文字を集めたものです。( *E* lasticSearch、*F* luentd、*K* ibana)

クラスタのロギングコンポーネントは、Elasticsearch、Fluentd、Kibana（EFK）をベースにしています。
コレクターである Fluentd は、OpenShift クラスタ内の各ノードにデプロイされています。
これはすべてのノードとコンテナのログを収集し、Elasticsearch（ES）に書き込みます。
Kibana は一元化された Web UI で、ユーザーや管理者は集約されたデータを使ってリッチなビジュアライゼーションやダッシュボードを作成することができます。
管理者は、すべてのログを検索することができます。
アプリケーションの所有者や開発者は、プロジェクトに属するログへのアクセスを許可することができます。
EFK スタックは OpenShift の上で動作します。

[WARNING]
====
このラボでは、infra-nodes ラボを完了していることが必要です。
ロギングスタックはそのラボで作成された `infra` ノードにインストールされます。
====

[NOTE]
====
詳細は、以下にあるOpenShiftの公式ドキュメントサイトに記載されています。:
 https://docs.openshift.com/container-platform/4.1/logging/efk-logging.html
====

[NOTE]
====
この演習は、ほぼすべて OpenShift の Web コンソールを使用して行われます。
ウェブコンソールとのやりとりはすべて、事実上バックグラウンドで API オブジェクトを作成または操作しています。
プロセスを完全に自動化したり、CLIや他のツールを使用して行うことも可能ですが、これらの方法は現時点では、この演習やドキュメントではカバーされていません。
====

### OpenShift ロギングをデプロイする

OpenShift Container Platform クラスタロギングは、デフォルト構成で使用するように設計されており、中小規模の OpenShift Container Platform クラスタ向けに調整されています。
以降のインストール手順には、サンプルの Cluster Logging Custom Resource（CR）が含まれており、これを使用してクラスタロギングインスタンスを作成し、クラスタロギングの導入を構成することができます。

デフォルトのクラスタロギングインストールを使用する場合は、サンプルCRを直接使用できます。

配置をカスタマイズしたい場合は、必要に応じてサンプル CR に変更を加えます。
以下では、Cluster Logging インスタンスのインストール時に行うことができる構成、またはインストール後に変更することができる構成について説明します。
Cluster Logging Custom Resource の外でできる変更を含め、各コンポーネントでの作業の詳細については、「構成」のセクションを参照してください。

#### `openshift-logging` namespace を作成する

OpenShift Logging は、独自の名前空間 `openshift-logging` 内で実行されます。
この名前空間はデフォルトでは存在せず、ロギングをインストールする前に作成する必要があります。
名前空間は yaml 形式で以下のように表されます。:

[source,yaml]
.openshift_logging_namespace.yaml
----
apiVersion: v1
kind: Namespace
metadata:
  name: openshift-logging
  annotations:
    openshift.io/node-selector: ""
  labels:
    openshift.io/cluster-logging: "true"
    openshift.io/cluster-monitoring: "true"
----

ネームスペースを作成するには、以下のコマンドを実行します。:

[source,bash,role="execute"]
----
oc create -f {{ HOME_PATH }}/support/openshift_logging_namespace.yaml
----


#### `Elasticsearch` と `Cluster Logging` Operator をクラスターにインストールする

`EFK` スタックをクラスタにインストールして設定するには、追加の Operator をインストールする必要があります。
これらは、クラスタ内から `Operator Hub` から GUI を介してインストールすることができます。

OpenShift で Operator を使用する際には、Operator を構成するいくつかの基本的な原理を理解しておくことが重要です。
`CustomResourceDefinion (CRD)` と `CustomResource (CR)` は、簡単に説明する 2 つの Kubernetes オブジェクトです。
`CRD` は、ジェネリックな事前定義された、データの構造体です。
Operator は、`CRD` で定義されたデータをどのように適用するかを理解します。
プログラミング的には、`CRD` はクラスに似ていると考えることができます。
`CustomResource (CR)` は、構造化されたデータが実際の値を持つ `CRD` の実際の実装です。
これらの値は、オペレータがサービスを設定するときに使用するものです。
繰り返しになりますが、プログラミング用語では、`CR` はクラスのインスタンス化されたオブジェクトに似ています。

Operator を使用するための一般的なパターンは、まず Operator をインストールし、必要な `CRD` を作成します。
`CRD` が作成された後、どのように動作するか、何をインストールするか、何を設定するかをオペレータに伝える `CR` を作成します。
openshift-logging　をインストールするには、このパターンに従います。

まず、OpenShift ClusterのGUIにログインします。
`{{ MASTER_URL }}`

その後、以下の手順に従ってください。:

1. Elasticsearch Operator のインストール:
  a. OpenShift コンソールから、 `Operators` → `OperatorHub`をクリックします。
  b. `Elasticsearch Operator` を、可能なら Operator リストから選択し、 `Install` をクリックします。
  c. `Create Operator Subscription` ページで、*Update Channel 4.2* を選択し、他のすべてのデフォルト設定をそのままに、`Subscribe`　をクリックします。
+
これにより、この OpenShift Container Platform クラスタを使用するすべてのユーザーとプロジェクトがこの Operator を利用できるようになります。

2. Cluster Logging Operator のインストール:
+
[NOTE]
====
`Cluster Logging` Operator を  `openshift-logging` ネームスペースにインストールする必要があります。
`openshift-logging` ネームスペースが前の手順で作成されたことを確認してください。
====

  a. OpenShift コンソールで、`Operators` → `OperatorHub` をクリックします。
  b. 利用可能な Operator のリストから `Cluster Logging` を選択し、`Install` をクリックする。
  c. `Create Operator Subscription` ページで、`Installation Mode` で、クラスタ上の特定の名前空間が選択されていることを確認し、`openshift-logging` を選択します。
     さらに、*select Update Channel 4.2* を選択し、他のすべてのデフォルトを残してから `Subscribe` をクリックします。

3. Operator のインストールを確認する。:

  a. Switch to the `Operators` → `Installed Operators` page.

  b. Make sure the `openshift-logging` project is selected.

  c. In the _Status_ column you should see green checks with either
     `InstallSucceeded` or `Copied` and the text _Up to date_.
+
[NOTE]
====
During installation an operator might display a `Failed` status. If the
operator then installs with an `InstallSucceeded` message, you can safely
ignore the `Failed` message.
====

4. Troubleshooting (optional)
+
If either operator does not appear as installed, to troubleshoot further:
+
* On the Copied tab of the Installed Operators page, if an operator show a
  Status of Copied, this indicates the installation is in process and is
  expected behavior.
+
* Switch to the Catalog → Operator Management page and inspect the Operator
  Subscriptions and Install Plans tabs for any failure or errors under Status.
+
* Switch to the Workloads → Pods page and check the logs in any Pods in the
  openshift-logging and openshift-operators projects that are reporting issues.


#### Create the Loggging `CustomResource (CR)` instance

Now that we have the operators installed, along with the `CRDs`, we can now
kick off the logging install by creating a Logging `CR`. This will define how
we want to install and configure logging.


1. In the OpenShift Console, switch to the the `Administration` → `Custom Resource Definitions` page.

2. On the `Custom Resource Definitions` page, click `ClusterLogging`.

3. On the `Custom Resource Definition Overview` page, select `View Instances` from the `Actions` menu.
+
[NOTE]
====
If you see a `404` error, don't panic. While the operator installation
succeeded, the operator itself has not finished installing and the
`CustomResourceDefinition` may not have been created yet. Wait a few moments
and then refresh the page.
====
+
4. On the `Cluster Loggings` page, click `Create Cluster Logging`.
+
[WARNING]
====
This step requires that you have completed the `Deploying and Managing OpenShift Container Storage` Module. If you have not completed the `OCS` module, you will need to substitute `storageClassName: ocs-storagecluster-ceph-rbd` with `storageClassName: gp2` in the `YAML` below before copying to the editor. 
====

5. In the `YAML` editor, replace the code with the following:

[source,yaml]
.openshift_logging_cr.yaml
----
apiVersion: "logging.openshift.io/v1"
kind: "ClusterLogging"
metadata:
  name: "instance"
  namespace: "openshift-logging"
spec:
  managementState: "Managed"
  logStore:
    type: "elasticsearch"
    elasticsearch:
      nodeCount: 3
      storage:
         storageClassName: ocs-storagecluster-ceph-rbd
         size: 100Gi
      redundancyPolicy: "SingleRedundancy"
      nodeSelector:
        node-role.kubernetes.io/infra: ""
      resources:
        request:
          memory: 4G
  visualization:
    type: "kibana"
    kibana:
      replicas: 1
      nodeSelector:
        node-role.kubernetes.io/infra: ""
  curation:
    type: "curator"
    curator:
      schedule: "30 3 * * *"
      nodeSelector:
        node-role.kubernetes.io/infra: ""
  collection:
    logs:
      type: "fluentd"
      fluentd: {}
      nodeSelector:
        node-role.kubernetes.io/infra: ""
----

Then click `Create`.

#### Verify the Loggging install

Now that Logging has been created, let's verify that things are working.

1. Switch to the `Workloads` → `Pods` page.

2. Select the `openshift-logging` project.

You should see pods for cluster logging (the operator itself), Elasticsearch,
and Fluentd, and Kibana.

Alternatively, you can verify from the command line by using the following command:

[source,bash,role="execute"]
----
oc get pods -n openshift-logging
----

You should eventually see something like:

----
NAME                                            READY   STATUS    RESTARTS   AGE
cluster-logging-operator-cb795f8dc-xkckc        1/1     Running   0          32m
elasticsearch-cdm-b3nqzchd-1-5c6797-67kfz       2/2     Running   0          14m
elasticsearch-cdm-b3nqzchd-2-6657f4-wtprv       2/2     Running   0          14m
elasticsearch-cdm-b3nqzchd-3-588c65-clg7g       2/2     Running   0          14m
fluentd-2c7dg                                   1/1     Running   0          14m
fluentd-9z7kk                                   1/1     Running   0          14m
fluentd-br7r2                                   1/1     Running   0          14m
fluentd-fn2sb                                   1/1     Running   0          14m
fluentd-pb2f8                                   1/1     Running   0          14m
fluentd-zqgqx                                   1/1     Running   0          14m
kibana-7fb4fd4cc9-bvt4p                         2/2     Running   0          14m
----

The _Fluentd_ *Pods* are deployed as part of a *DaemonSet*, which is a mechanism
to ensure that specific *Pods* run on specific *Nodes* in the cluster at all
times:

[source,bash,role="execute"]
----
oc get daemonset -n openshift-logging
----

You will see something like:

----
NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE SELECTOR            AGE
fluentd   9         9         9       9            9           kubernetes.io/os=linux   94s
----

You should expect 1 `fluentd` *Pod* for every *Node* in your cluster.
Remember that *Masters* are still *Nodes* and `fluentd` will run there, too,
to slurp the various logs.

You will also see the storage for ElasticSearch has been automatically
provisioned. If you query the *PersistentVolumeClaim* objects in this project you will see the new storage.

[source,bash,role="execute"]
----
oc get pvc -n openshift-logging
----

You will see something like:

----
NAME                                         STATUS   VOLUME                                     CAPACITY   ACCESS
MODES   STORAGECLASS                  AGE
elasticsearch-elasticsearch-cdm-ggzilasv-1   Bound    pvc-f3239564-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
elasticsearch-elasticsearch-cdm-ggzilasv-2   Bound    pvc-f324a252-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
elasticsearch-elasticsearch-cdm-ggzilasv-3   Bound    pvc-f326aa7d-389c-11ea-bab2-06ca7918708a   100Gi      RWO
        ocs-storagecluster-ceph-rbd   15m
----		

[NOTE]
====
Much like with the Metrics solution, we defined the appropriate
`NodeSelector` in the Logging configuration (`CR`) to ensure that the Logging
components only landed on the infra nodes. That being said, the `DaemonSet`
ensures FluentD runs on *all* nodes. Otherwise we would not capture all of
the container logs.
====

#### Accessing _Kibana_

As mentioned before, _Kibana_ is the front end and the way that users and
admins may access the OpenShift Logging stack. To reach the _Kibana_ user
interface, first determine its public access URL by querying the *Route* that
got set up to expose Kibana's *Service*:

To find and access the _Kibana_ route:

1. In the OpenShift console, click on the `Networking` → `Routes` page.

2. Select the `openshift-logging` project.

3. Click on the `Kibana` route.

4. In the `Location` field, click on the URL presented.

5. Click through and accept the SSL certificates

Alternatively, this can be obtained from the command line:

[source,bash,role="execute"]
----
oc get route -n openshift-logging
----

You will see something like:

----
NAME     HOST/PORT                                                           PATH   SERVICES   PORT    TERMINATION          WILDCARD
kibana   kibana-openshift-logging.{{ ROUTE_SUBDOMAIN }}          kibana     <all>   reencrypt/Redirect   None
----

Or, you can control+click the link:

https://kibana-openshift-logging.{{ ROUTE_SUBDOMAIN }}

There is a special authentication proxy that is configured as part of the EFK
installation that results in Kibana requiring OpenShift credentials for
access.

Because you've already authenticated to the OpenShift Console as a
cluster-admin user, you will see an administrative view of what Kibana has to
show you (which you authorized by clicking the button).

#### Queries with _Kibana_

Once the _Kibana_ web interface is up, we are now able to do queries.
_Kibana_ offers a the user a powerful interface to query all logs that come
from the cluster.

By default, _Kibana_ will show all logs that have been received within the
the last 15 minutes. This time interval may be changed in the upper right
hand corner. The log messages are shown in the middle of the page. All log
messages that are received are indexed based on the log message content. Each
message will have fields associated that are associated to that log message.
To see the fields that make up an individual message, click on the arrow on
the side of each message located in the center of the page. This will show
the message fields that are contained.

First, set the default index pattern to `.all`. On the left hand side towards
the top, in the drop down menu select the `.all` index pattern.

To select fields to show for messages, look on left hand side fore the
`Available Fields` label. Below this are fields that can be selected and
shown in the middle of the screen. Find the `hostname` field below the
`Available Fields` and click `add`. Notice now, in the message pain, each
message's hostname is displayed. More fields may be added. Click the `add`
button for `kubernetes.pod_name` and also for `message`.

To create a query for logs, the `Add a filter +` link right below the search
box may be used. This will allow us to build queries using the fields of the
messages. For example, if we wanted to see all log messages from the
`openshift-logging` namespace, we can do the following:

1. Click on `Add a filter +`.

2. In the `Fields` input box, start typing `kubernetes.namespace_name`.
Notice all of the available fields that we can use to build the query

3. Next, select `is`.

4. In the `Value` field, type in `openshift-logging`

5. Click the "Save" button

Now, in the center of the screen you will see all of the logs from all the
pods in the `openshift-logging` namespace.

Of course, you may add more filters to refine the query.

One other neat option that Kibana allows you to do is save queries to use for
later. To save a query do the following:

1. click on `Save` at the top of the screen.

2. Type in the name you would like to save it as. In this case, let's type in
`openshift-logging Namespace`

Once this has been saved, it can be used at a later time by hitting the
`Open` button and selecting this query.

Please take time to explore the _Kibana_ page and get experience by adding
and doing more queries. This will be helpful when using a production cluster,
you will be able to get the exact logs that you are looking for in a single
place.
